{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled23.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNeAwodPrqKnazEN1yNUYE+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zzzle96/PyTorch/blob/master/MM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ex6vhG2zwP9K",
        "outputId": "812c4d6c-d257-44ec-e53e-aa24acbb649b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "!git clone https://github.com/jhhuang96/ConvLSTM-PyTorch"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'ConvLSTM-PyTorch'...\n",
            "remote: Enumerating objects: 108, done.\u001b[K\n",
            "remote: Counting objects: 100% (108/108), done.\u001b[K\n",
            "remote: Compressing objects: 100% (88/88), done.\u001b[K\n",
            "remote: Total 108 (delta 52), reused 59 (delta 18), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (108/108), 9.50 MiB | 15.98 MiB/s, done.\n",
            "Resolving deltas: 100% (52/52), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m84lpH2HwohJ",
        "outputId": "b2ede5ec-e04b-4d83-e425-a3ca2d33fa85",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "import sys\n",
        "sys.path.append('/content/ConvLSTM-PyTorch')\n",
        "print(sys.path)\n",
        "\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['', '/env/python', '/usr/lib/python36.zip', '/usr/lib/python3.6', '/usr/lib/python3.6/lib-dynload', '/usr/local/lib/python3.6/dist-packages', '/usr/lib/python3/dist-packages', '/usr/local/lib/python3.6/dist-packages/IPython/extensions', '/root/.ipython', '/content/ConvLSTM-PyTorch']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kgUI9CqN0bNF",
        "outputId": "e6814600-8e3c-478c-9cd4-57831422c4fc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 174
        }
      },
      "source": [
        "pip install tensorboardX"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorboardX\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/af/0c/4f41bcd45db376e6fe5c619c01100e9b7531c55791b7244815bac6eac32c/tensorboardX-2.1-py2.py3-none-any.whl (308kB)\n",
            "\r\u001b[K     |█                               | 10kB 16.3MB/s eta 0:00:01\r\u001b[K     |██▏                             | 20kB 1.8MB/s eta 0:00:01\r\u001b[K     |███▏                            | 30kB 2.2MB/s eta 0:00:01\r\u001b[K     |████▎                           | 40kB 2.5MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 51kB 2.0MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 61kB 2.3MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 71kB 2.5MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 81kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 92kB 2.9MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 102kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 112kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 122kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 133kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 143kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████                | 153kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 163kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 174kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 184kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 194kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 204kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 215kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 225kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 235kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 245kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 256kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 266kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 276kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 286kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 296kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 307kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 317kB 2.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorboardX) (3.12.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from tensorboardX) (1.15.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from tensorboardX) (1.18.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.8.0->tensorboardX) (50.3.0)\n",
            "Installing collected packages: tensorboardX\n",
            "Successfully installed tensorboardX-2.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ret9KoFKqtnf"
      },
      "source": [
        "import os\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
        "from encoder import Encoder\n",
        "from decoder import Decoder\n",
        "from model import ED\n",
        "from net_params import convlstm_encoder_params, convlstm_decoder_params, convgru_encoder_params, convgru_decoder_params\n",
        "from data.mm import MovingMNIST\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.optim import lr_scheduler\n",
        "import torch.optim as optim\n",
        "import sys\n",
        "from earlystopping import EarlyStopping\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "from tensorboardX import SummaryWriter\n",
        "import argparse\n",
        "%matplotlib inline\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "random_seed = 1996\n",
        "np.random.seed(random_seed)\n",
        "torch.manual_seed(random_seed)\n",
        "if torch.cuda.device_count() > 1:\n",
        "    torch.cuda.manual_seed_all(random_seed)\n",
        "else:\n",
        "    torch.cuda.manual_seed(random_seed)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "\n",
        "save_dir = './save_model/' + TIMESTAMP\n",
        "\n",
        "trainFolder = MovingMNIST(is_train=True,\n",
        "                          root='/content/ConvLSTM-PyTorch/data',\n",
        "                          n_frames_input=10,\n",
        "                          n_frames_output=10,\n",
        "                          num_objects=[3])\n",
        "validFolder = MovingMNIST(is_train=False,\n",
        "                          root='/content/ConvLSTM-PyTorch/data',\n",
        "                          n_frames_input=10,\n",
        "                          n_frames_output=10,\n",
        "                          num_objects=[3])\n",
        "trainLoader = torch.utils.data.DataLoader(trainFolder,\n",
        "                                          batch_size=1,\n",
        "                                          shuffle=False)\n",
        "validLoader = torch.utils.data.DataLoader(validFolder,\n",
        "                                          batch_size=1,\n",
        "                                          shuffle=False)\n",
        "\n"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dN7awvnxsOl2"
      },
      "source": [
        "def imshow (img):\n",
        "    img = img/ 2+0.5\n",
        "    np_img = img.numpy()\n",
        "    plt.imshow(np_img)\n",
        "    #plt.imshow(np.transpose(np_img, (1,0,2,3,4)))\n",
        "    print(np_img.shape)"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jHsKxlKP7o38",
        "outputId": "5178ccd7-94f7-451c-bc7c-39934d5b26c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 602
        }
      },
      "source": [
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "dataiter = iter(trainLoader)\n",
        "batch,images1 , images2, images3, labels = dataiter.next()\n",
        "#images1 = dataiter.next()\n",
        "images1 = images1[0]\n",
        "imshow(torchvision.utils.make_grid(images1))"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-74-10fe77177da1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#images1 = dataiter.next()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mimages1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_grid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-68-10a173425a45>\u001b[0m in \u001b[0;36mimshow\u001b[0;34m(img)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m/\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mnp_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp_img\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;31m#plt.imshow(np.transpose(np_img, (1,0,2,3,4)))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp_img\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mimshow\u001b[0;34m(X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, shape, filternorm, filterrad, imlim, resample, url, data, **kwargs)\u001b[0m\n\u001b[1;32m   2649\u001b[0m         \u001b[0mfilternorm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilternorm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilterrad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilterrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimlim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimlim\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2650\u001b[0m         resample=resample, url=url, **({\"data\": data} if data is not\n\u001b[0;32m-> 2651\u001b[0;31m         None else {}), **kwargs)\n\u001b[0m\u001b[1;32m   2652\u001b[0m     \u001b[0msci\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__ret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2653\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m__ret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1563\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1565\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msanitize_sequence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1566\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1567\u001b[0m         \u001b[0mbound\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_sig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/cbook/deprecation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    356\u001b[0m                 \u001b[0;34mf\"%(removal)s.  If any parameter follows {name!r}, they \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m                 f\"should be pass as keyword, not positionally.\")\n\u001b[0;32m--> 358\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/cbook/deprecation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    356\u001b[0m                 \u001b[0;34mf\"%(removal)s.  If any parameter follows {name!r}, they \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m                 f\"should be pass as keyword, not positionally.\")\n\u001b[0;32m--> 358\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mimshow\u001b[0;34m(self, X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, shape, filternorm, filterrad, imlim, resample, url, **kwargs)\u001b[0m\n\u001b[1;32m   5624\u001b[0m                               resample=resample, **kwargs)\n\u001b[1;32m   5625\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5626\u001b[0;31m         \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5627\u001b[0m         \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_alpha\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5628\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_clip_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/image.py\u001b[0m in \u001b[0;36mset_data\u001b[0;34m(self, A)\u001b[0m\n\u001b[1;32m    697\u001b[0m                 or self._A.ndim == 3 and self._A.shape[-1] in [3, 4]):\n\u001b[1;32m    698\u001b[0m             raise TypeError(\"Invalid shape {} for image data\"\n\u001b[0;32m--> 699\u001b[0;31m                             .format(self._A.shape))\n\u001b[0m\u001b[1;32m    700\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_A\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: Invalid shape (3, 134, 530) for image data"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQYAAAD8CAYAAACVSwr3AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAMbElEQVR4nO3bcYikd33H8ffHXFNpGrWYFeTuNJFeGq+2kHRJU4SaYlouKdz9YZE7CG1KyKE1UlAKKZZU4l9WakG41l6pRAWNp3+UBU8CtZGAeDEbEmPuQmQ9bXNRmjOm/iMaQ7/9YybtZL+7mSd3szO39f2ChXme+e3Md4fhfc8881yqCkma9IpFDyDpwmMYJDWGQVJjGCQ1hkFSYxgkNVPDkOQTSZ5O8tgm9yfJx5KsJXk0yTWzH1PSPA05Yrgb2PcS998I7Bn/HAb+4fzHkrRIU8NQVfcDP3yJJQeAT9XICeA1SV4/qwElzd+OGTzGTuDJie0z433fX78wyWFGRxVccsklv3XVVVfN4Oklbeahhx76QVUtvdzfm0UYBquqo8BRgOXl5VpdXZ3n00s/d5L8+7n83iy+lXgK2D2xvWu8T9I2NYswrAB/PP524jrgR1XVPkZI2j6mfpRI8lngeuCyJGeAvwZ+AaCqPg4cB24C1oAfA3+6VcNKmo+pYaiqQ1PuL+A9M5tI0sJ55aOkxjBIagyDpMYwSGoMg6TGMEhqDIOkxjBIagyDpMYwSGoMg6TGMEhqDIOkxjBIagyDpMYwSGoMg6TGMEhqDIOkxjBIagyDpMYwSGoMg6TGMEhqDIOkxjBIagyDpMYwSGoMg6TGMEhqDIOkxjBIagyDpMYwSGoMg6RmUBiS7EvyRJK1JHdscP8bktyX5OEkjya5afajSpqXqWFIchFwBLgR2AscSrJ33bK/Ao5V1dXAQeDvZz2opPkZcsRwLbBWVaer6jngHuDAujUFvGp8+9XA92Y3oqR5GxKGncCTE9tnxvsmfRC4OckZ4Djw3o0eKMnhJKtJVs+ePXsO40qah1mdfDwE3F1Vu4CbgE8naY9dVUerarmqlpeWlmb01JJmbUgYngJ2T2zvGu+bdCtwDKCqvga8ErhsFgNKmr8hYXgQ2JPkiiQXMzq5uLJuzX8AbwdI8mZGYfCzgrRNTQ1DVT0P3A7cCzzO6NuHk0nuSrJ/vOz9wG1JvgF8Frilqmqrhpa0tXYMWVRVxxmdVJzcd+fE7VPAW2c7mqRF8cpHSY1hkNQYBkmNYZDUGAZJjWGQ1BgGSY1hkNQYBkmNYZDUGAZJjWGQ1BgGSY1hkNQYBkmNYZDUGAZJjWGQ1BgGSY1hkNQYBkmNYZDUGAZJjWGQ1BgGSY1hkNQYBkmNYZDUGAZJjWGQ1BgGSY1hkNQYBkmNYZDUDApDkn1JnkiyluSOTda8M8mpJCeTfGa2Y0qapx3TFiS5CDgC/D5wBngwyUpVnZpYswf4S+CtVfVsktdt1cCStt6QI4ZrgbWqOl1VzwH3AAfWrbkNOFJVzwJU1dOzHVPSPA0Jw07gyYntM+N9k64Erkzy1SQnkuzb6IGSHE6ymmT17Nmz5zaxpC03q5OPO4A9wPXAIeCfkrxm/aKqOlpVy1W1vLS0NKOnljRrQ8LwFLB7YnvXeN+kM8BKVf2sqr4DfItRKCRtQ0PC8CCwJ8kVSS4GDgIr69b8C6OjBZJcxuijxekZzilpjqaGoaqeB24H7gUeB45V1ckkdyXZP152L/BMklPAfcBfVNUzWzW0pK2VqlrIEy8vL9fq6upCnlv6eZHkoapafrm/55WPkhrDIKkxDJIawyCpMQySGsMgqTEMkhrDIKkxDJIawyCpMQySGsMgqTEMkhrDIKkxDJIawyCpMQySGsMgqTEMkhrDIKkxDJIawyCpMQySGsMgqTEMkhrDIKkxDJIawyCpMQySGsMgqTEMkhrDIKkxDJIawyCpMQySmkFhSLIvyRNJ1pLc8RLr3pGkkizPbkRJ8zY1DEkuAo4ANwJ7gUNJ9m6w7lLgz4EHZj2kpPkacsRwLbBWVaer6jngHuDABus+BHwY+MkM55O0AEPCsBN4cmL7zHjf/0pyDbC7qr74Ug+U5HCS1SSrZ8+efdnDSpqP8z75mOQVwEeB909bW1VHq2q5qpaXlpbO96klbZEhYXgK2D2xvWu87wWXAm8BvpLku8B1wIonIKXta0gYHgT2JLkiycXAQWDlhTur6kdVdVlVXV5VlwMngP1VtbolE0vaclPDUFXPA7cD9wKPA8eq6mSSu5Ls3+oBJc3fjiGLquo4cHzdvjs3WXv9+Y8laZG88lFSYxgkNYZBUmMYJDWGQVJjGCQ1hkFSYxgkNYZBUmMYJDWGQVJjGCQ1hkFSYxgkNYZBUmMYJDWGQVJjGCQ1hkFSYxgkNYZBUmMYJDWGQVJjGCQ1hkFSYxgkNYZBUmMYJDWGQVJjGCQ1hkFSYxgkNYZBUmMYJDWDwpBkX5InkqwluWOD+9+X5FSSR5N8OckbZz+qpHmZGoYkFwFHgBuBvcChJHvXLXsYWK6q3wS+APzNrAeVND9DjhiuBdaq6nRVPQfcAxyYXFBV91XVj8ebJ4Bdsx1T0jwNCcNO4MmJ7TPjfZu5FfjSRnckOZxkNcnq2bNnh08paa5mevIxyc3AMvCRje6vqqNVtVxVy0tLS7N8akkztGPAmqeA3RPbu8b7XiTJDcAHgLdV1U9nM56kRRhyxPAgsCfJFUkuBg4CK5MLklwN/COwv6qenv2YkuZpahiq6nngduBe4HHgWFWdTHJXkv3jZR8Bfhn4fJJHkqxs8nCStoEhHyWoquPA8XX77py4fcOM55K0QF75KKkxDJIawyCpMQySGsMgqTEMkhrDIKkxDJIawyCpMQySGsMgqTEMkhrDIKkxDJIawyCpMQySGsMgqTEMkhrDIKkxDJIawyCpMQySGsMgqTEMkhrDIKkxDJIawyCpMQySGsMgqTEMkhrDIKkxDJIawyCpMQySGsMgqRkUhiT7kjyRZC3JHRvc/4tJPje+/4Ekl896UEnzMzUMSS4CjgA3AnuBQ0n2rlt2K/BsVf0q8HfAh2c9qKT5GXLEcC2wVlWnq+o54B7gwLo1B4BPjm9/AXh7ksxuTEnztGPAmp3AkxPbZ4Df3mxNVT2f5EfAa4EfTC5Kchg4PN78aZLHzmXoBbmMdX/PBWw7zQrba97tNCvAr53LLw0Jw8xU1VHgKECS1apanufzn4/tNO92mhW217zbaVYYzXsuvzfko8RTwO6J7V3jfRuuSbIDeDXwzLkMJGnxhoThQWBPkiuSXAwcBFbWrVkB/mR8+4+Af6uqmt2YkuZp6keJ8TmD24F7gYuAT1TVySR3AatVtQL8M/DpJGvADxnFY5qj5zH3ImynebfTrLC95t1Os8I5zhv/YZe0nlc+SmoMg6Rmy8OwnS6nHjDr+5KcSvJoki8neeMi5pyY5yXnnVj3jiSVZGFfsw2ZNck7x6/vySSfmfeM62aZ9l54Q5L7kjw8fj/ctIg5x7N8IsnTm10XlJGPjf+WR5NcM/VBq2rLfhidrPw28CbgYuAbwN51a/4M+Pj49kHgc1s503nO+nvAL41vv3tRsw6dd7zuUuB+4ASwfKHOCuwBHgZ+Zbz9ugv5tWV0Uu/d49t7ge8ucN7fBa4BHtvk/puALwEBrgMemPaYW33EsJ0up546a1XdV1U/Hm+eYHRNx6IMeW0BPsTo/678ZJ7DrTNk1tuAI1X1LEBVPT3nGScNmbeAV41vvxr43hzne/EgVfcz+jZwMweAT9XICeA1SV7/Uo+51WHY6HLqnZutqarngRcup563IbNOupVRhRdl6rzjQ8bdVfXFeQ62gSGv7ZXAlUm+muREkn1zm64bMu8HgZuTnAGOA++dz2jn5OW+t+d7SfT/F0luBpaBty16ls0keQXwUeCWBY8y1A5GHyeuZ3Qkdn+S36iq/1roVJs7BNxdVX+b5HcYXcfzlqr670UPNgtbfcSwnS6nHjIrSW4APgDsr6qfzmm2jUyb91LgLcBXknyX0WfLlQWdgBzy2p4BVqrqZ1X1HeBbjEKxCEPmvRU4BlBVXwNeyeg/WF2IBr23X2SLT4rsAE4DV/B/J3F+fd2a9/Dik4/HFnQCZ8isVzM6KbVnETO+3HnXrf8Kizv5OOS13Qd8cnz7MkaHvq+9gOf9EnDL+PabGZ1jyALfD5ez+cnHP+TFJx+/PvXx5jDwTYzq/23gA+N9dzH6FxdGpf08sAZ8HXjTAl/cabP+K/CfwCPjn5VFzTpk3nVrFxaGga9tGH30OQV8Ezh4Ib+2jL6J+Oo4Go8Af7DAWT8LfB/4GaMjr1uBdwHvmnhtj4z/lm8OeR94SbSkxisfJTWGQVJjGCQ1hkFSYxgkNYZBUmMYJDX/AwqkUdV2nfELAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_iRFJlm_9Uic",
        "outputId": "ceff9557-bcd6-43c7-fade-78425c6adfce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        }
      },
      "source": [
        "print(images.shape)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-30-2b0681aeae8b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'shape'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LI4udm8GyPSH",
        "outputId": "a6ece56a-b473-4b58-c55c-414cf1a3e584",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "|#!/usr/bin/env python\n",
        "# -*- encoding: utf-8 -*-\n",
        "'''\n",
        "@File    :   main.py\n",
        "@Time    :   2020/03/09\n",
        "@Author  :   jhhuang96\n",
        "@Mail    :   hjh096@126.com\n",
        "@Version :   1.0\n",
        "@Description:   \n",
        "'''\n",
        "\n",
        "import os\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
        "from encoder import Encoder\n",
        "from decoder import Decoder\n",
        "from model import ED\n",
        "from net_params import convlstm_encoder_params, convlstm_decoder_params, convgru_encoder_params, convgru_decoder_params\n",
        "from data.mm import MovingMNIST\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.optim import lr_scheduler\n",
        "import torch.optim as optim\n",
        "import sys\n",
        "from earlystopping import EarlyStopping\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "from tensorboardX import SummaryWriter\n",
        "import argparse\n",
        "\n",
        "TIMESTAMP = \"2020-03-09T00-00-00\"                         \n",
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument('-clstm',\n",
        "                    '--convlstm',\n",
        "                    help='use convlstm as base cell',\n",
        "                    action='store_true')\n",
        "parser.add_argument('-cgru',\n",
        "                    '--convgru',\n",
        "                    help='use convgru as base cell',\n",
        "                    action='store_true')\n",
        "parser.add_argument('--batch_size',\n",
        "                    default=4,\n",
        "                    type=int,\n",
        "                    help='mini-batch size')\n",
        "parser.add_argument('-lr', default=1e-4, type=float, help='G learning rate')\n",
        "parser.add_argument('-frames_input',\n",
        "                    default=10,\n",
        "                    type=int,\n",
        "                    help='sum of input frames')\n",
        "parser.add_argument('-frames_output',\n",
        "                    default=10,\n",
        "                    type=int,\n",
        "                    help='sum of predict frames')\n",
        "parser.add_argument('-epochs', default=500, type=int, help='sum of epochs')\n",
        "args = parser.parse_args()\n",
        "\n",
        "random_seed = 1996\n",
        "np.random.seed(random_seed)\n",
        "torch.manual_seed(random_seed)\n",
        "if torch.cuda.device_count() > 1:\n",
        "    torch.cuda.manual_seed_all(random_seed)\n",
        "else:\n",
        "    torch.cuda.manual_seed(random_seed)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "\n",
        "save_dir = './save_model/' + TIMESTAMP\n",
        "\n",
        "trainFolder = MovingMNIST(is_train=True,\n",
        "                          root='data/',\n",
        "                          n_frames_input=args.frames_input,\n",
        "                          n_frames_output=args.frames_output,\n",
        "                          num_objects=[3])\n",
        "validFolder = MovingMNIST(is_train=False,\n",
        "                          root='data/',\n",
        "                          n_frames_input=args.frames_input,\n",
        "                          n_frames_output=args.frames_output,\n",
        "                          num_objects=[3])\n",
        "trainLoader = torch.utils.data.DataLoader(trainFolder,\n",
        "                                          batch_size=args.batch_size,\n",
        "                                          shuffle=False)\n",
        "validLoader = torch.utils.data.DataLoader(validFolder,\n",
        "                                          batch_size=args.batch_size,\n",
        "                                          shuffle=False)\n",
        "\n",
        "if args.convlstm:\n",
        "    encoder_params = convlstm_encoder_params\n",
        "    decoder_params = convlstm_decoder_params\n",
        "if args.convgru:\n",
        "    encoder_params = convgru_encoder_params\n",
        "    decoder_params = convgru_decoder_params\n",
        "else:\n",
        "    encoder_params = convgru_encoder_params\n",
        "    decoder_params = convgru_decoder_params\n",
        "\n",
        "\n",
        "def train():\n",
        "    '''\n",
        "    main function to run the training\n",
        "    '''\n",
        "    encoder = Encoder(encoder_params[0], encoder_params[1]).cuda()\n",
        "    decoder = Decoder(decoder_params[0], decoder_params[1]).cuda()\n",
        "    net = ED(encoder, decoder)\n",
        "    run_dir = './runs/' + TIMESTAMP\n",
        "    if not os.path.isdir(run_dir):\n",
        "        os.makedirs(run_dir)\n",
        "    tb = SummaryWriter(run_dir)\n",
        "    # initialize the early_stopping object\n",
        "    early_stopping = EarlyStopping(patience=20, verbose=True)\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    if torch.cuda.device_count() > 1:\n",
        "        net = nn.DataParallel(net)\n",
        "    net.to(device)\n",
        "\n",
        "    if os.path.exists(os.path.join(save_dir, 'checkpoint.pth.tar')):\n",
        "        # load existing model\n",
        "        print('==> loading existing model')\n",
        "        model_info = torch.load(os.path.join(save_dir, 'checkpoin.pth.tar'))\n",
        "        net.load_state_dict(model_info['state_dict'])\n",
        "        optimizer = torch.optim.Adam(net.parameters())\n",
        "        optimizer.load_state_dict(model_info['optimizer'])\n",
        "        cur_epoch = model_info['epoch'] + 1\n",
        "    else:\n",
        "        if not os.path.isdir(save_dir):\n",
        "            os.makedirs(save_dir)\n",
        "        cur_epoch = 0\n",
        "    lossfunction = nn.MSELoss().cuda()\n",
        "    optimizer = optim.Adam(net.parameters(), lr=args.lr)\n",
        "    pla_lr_scheduler = lr_scheduler.ReduceLROnPlateau(optimizer,\n",
        "                                                      factor=0.5,\n",
        "                                                      patience=4,\n",
        "                                                      verbose=True)\n",
        "\n",
        "    # to track the training loss as the model trains\n",
        "    train_losses = []\n",
        "    # to track the validation loss as the model trains\n",
        "    valid_losses = []\n",
        "    # to track the average training loss per epoch as the model trains\n",
        "    avg_train_losses = []\n",
        "    # to track the average validation loss per epoch as the model trains\n",
        "    avg_valid_losses = []\n",
        "    # mini_val_loss = np.inf\n",
        "    for epoch in range(cur_epoch, args.epochs + 1):\n",
        "        ###################\n",
        "        # train the model #\n",
        "        ###################\n",
        "        t = tqdm(trainLoader, leave=False, total=len(trainLoader))\n",
        "        for i, (idx, targetVar, inputVar, _, _) in enumerate(t):\n",
        "            inputs = inputVar.to(device)  # B,S,C,H,W\n",
        "            label = targetVar.to(device)  # B,S,C,H,W\n",
        "            optimizer.zero_grad()\n",
        "            net.train()\n",
        "            pred = net(inputs)  # B,S,C,H,W\n",
        "            loss = lossfunction(pred, label)\n",
        "            loss_aver = loss.item() / args.batch_size\n",
        "            train_losses.append(loss_aver)\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_value_(net.parameters(), clip_value=10.0)\n",
        "            optimizer.step()\n",
        "            t.set_postfix({\n",
        "                'trainloss': '{:.6f}'.format(loss_aver),\n",
        "                'epoch': '{:02d}'.format(epoch)\n",
        "            })\n",
        "        tb.add_scalar('TrainLoss', loss_aver, epoch)\n",
        "        ######################\n",
        "        # validate the model #\n",
        "        ######################\n",
        "        with torch.no_grad():\n",
        "            net.eval()\n",
        "            t = tqdm(validLoader, leave=False, total=len(validLoader))\n",
        "            for i, (idx, targetVar, inputVar, _, _) in enumerate(t):\n",
        "                if i == 3000:\n",
        "                    break\n",
        "                inputs = inputVar.to(device)\n",
        "                label = targetVar.to(device)\n",
        "                pred = net(inputs)\n",
        "                loss = lossfunction(pred, label)\n",
        "                loss_aver = loss.item() / args.batch_size\n",
        "                # record validation loss\n",
        "                valid_losses.append(loss_aver)\n",
        "                #print (\"validloss: {:.6f},  epoch : {:02d}\".format(loss_aver,epoch),end = '\\r', flush=True)\n",
        "                t.set_postfix({\n",
        "                    'validloss': '{:.6f}'.format(loss_aver),\n",
        "                    'epoch': '{:02d}'.format(epoch)\n",
        "                })\n",
        "\n",
        "        tb.add_scalar('ValidLoss', loss_aver, epoch)\n",
        "        torch.cuda.empty_cache()\n",
        "        # print training/validation statistics\n",
        "        # calculate average loss over an epoch\n",
        "        train_loss = np.average(train_losses)\n",
        "        valid_loss = np.average(valid_losses)\n",
        "        avg_train_losses.append(train_loss)\n",
        "        avg_valid_losses.append(valid_loss)\n",
        "\n",
        "        epoch_len = len(str(args.epochs))\n",
        "\n",
        "        print_msg = (f'[{epoch:>{epoch_len}}/{args.epochs:>{epoch_len}}] ' +\n",
        "                     f'train_loss: {train_loss:.6f} ' +\n",
        "                     f'valid_loss: {valid_loss:.6f}')\n",
        "\n",
        "        print(print_msg)\n",
        "        # clear lists to track next epoch\n",
        "        train_losses = []\n",
        "        valid_losses = []\n",
        "        pla_lr_scheduler.step(valid_loss)  # lr_scheduler\n",
        "        model_dict = {\n",
        "            'epoch': epoch,\n",
        "            'state_dict': net.state_dict(),\n",
        "            'optimizer': optimizer.state_dict()\n",
        "        }\n",
        "        early_stopping(valid_loss.item(), model_dict, epoch, save_dir)\n",
        "        if early_stopping.early_stop:\n",
        "            print(\"Early stopping\")\n",
        "            break\n",
        "\n",
        "    with open(\"avg_train_losses.txt\", 'wt') as f:\n",
        "        for i in avg_train_losses:\n",
        "            print(i, file=f)\n",
        "\n",
        "    with open(\"avg_valid_losses.txt\", 'wt') as f:\n",
        "        for i in avg_valid_losses:\n",
        "            print(i, file=f)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    train()\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "usage: ipykernel_launcher.py [-h] [-clstm] [-cgru] [--batch_size BATCH_SIZE]\n",
            "                             [-lr LR] [-frames_input FRAMES_INPUT]\n",
            "                             [-frames_output FRAMES_OUTPUT] [-epochs EPOCHS]\n",
            "ipykernel_launcher.py: error: ambiguous option: -f could match -frames_input, -frames_output\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "SystemExit",
          "evalue": "ignored",
          "traceback": [
            "An exception has occurred, use %tb to see the full traceback.\n",
            "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
          ]
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2890: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
            "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "slHsve22y1aY"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}