{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Action_Recognition_From_HMDB51_dataset",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "1b4b786d8f1d4ccf90bef776ec7de493": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_43caf05ca8844aafb3f2e13a772f100a",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_ac1c8a5f31724bd7ababafe6bfbe0a18",
              "IPY_MODEL_b15ea291687f4fcc85efc66661e15699"
            ]
          }
        },
        "43caf05ca8844aafb3f2e13a772f100a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ac1c8a5f31724bd7ababafe6bfbe0a18": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_8aed90bbdd514c23a8bdc55473170a37",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 423,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 423,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f361fb2acae04ab7b0853d31bbd6808d"
          }
        },
        "b15ea291687f4fcc85efc66661e15699": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_f2dacdc81daa44fd8798b7ded497c665",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 423/423 [01:39&lt;00:00,  4.27it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_236f0af443ad42ab8020276058fc938f"
          }
        },
        "8aed90bbdd514c23a8bdc55473170a37": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f361fb2acae04ab7b0853d31bbd6808d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f2dacdc81daa44fd8798b7ded497c665": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "236f0af443ad42ab8020276058fc938f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ed31b429fab949de993d7ff902181b21": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_a1c86ea4f28b45bb865feda301f1444f",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_2d65a4ff56bf487b936551769023b271",
              "IPY_MODEL_1e0c1a9c619e478bb5656466e3f97ca5"
            ]
          }
        },
        "a1c86ea4f28b45bb865feda301f1444f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2d65a4ff56bf487b936551769023b271": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_ed8411a80bad41f7ae85186d309562ba",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 423,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 423,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2831b3a56cb240f48860674e39a38b1d"
          }
        },
        "1e0c1a9c619e478bb5656466e3f97ca5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_ce0aa727b8e84391b11092ee26120287",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 423/423 [02:54&lt;00:00,  2.43it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1d1e405b8f2b441e80e7762f7da8d5d1"
          }
        },
        "ed8411a80bad41f7ae85186d309562ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2831b3a56cb240f48860674e39a38b1d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ce0aa727b8e84391b11092ee26120287": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1d1e405b8f2b441e80e7762f7da8d5d1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zzzle96/PyTorch/blob/master/HMDB51%20recognition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TEDENnLoeqCJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "outputId": "22bbaa83-e9bb-41aa-d524-485752fc8803"
      },
      "source": [
        "# Install dependencies for video module in pytorch to work\n",
        "! apt-get install libavformat-dev libavdevice-dev\n",
        "! pip install av==6.2.0"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "libavdevice-dev is already the newest version (7:3.4.8-0ubuntu0.2).\n",
            "libavformat-dev is already the newest version (7:3.4.8-0ubuntu0.2).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 11 not upgraded.\n",
            "Collecting av==6.2.0\n",
            "  Using cached https://files.pythonhosted.org/packages/84/77/0be0fdaa3b7912c184705a4545ae6f1e9e47ab9e3834a3ef5caf2d7ca1e7/av-6.2.0.tar.gz\n",
            "Building wheels for collected packages: av\n",
            "  Building wheel for av (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for av: filename=av-6.2.0-cp36-cp36m-linux_x86_64.whl size=5003209 sha256=0fc62614f7ae008039ce9a6199bd0bc50497d18acb46689d18b9d4ec5ee86359\n",
            "  Stored in directory: /root/.cache/pip/wheels/2f/c1/b2/05e83d944cde5df317e4542082d67756ec4224c7885aee2d66\n",
            "Successfully built av\n",
            "Installing collected packages: av\n",
            "Successfully installed av-6.2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lZImwiJYlgoQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "outputId": "1de4d18e-5f6d-47b0-9f45-b95f0a133eb5"
      },
      "source": [
        "# Download HMDB51 data and splits from serre lab website\n",
        "! wget http://serre-lab.clps.brown.edu/wp-content/uploads/2013/10/hmdb51_org.rar\n",
        "! wget http://serre-lab.clps.brown.edu/wp-content/uploads/2013/10/test_train_splits.rar"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-09-15 00:39:46--  http://serre-lab.clps.brown.edu/wp-content/uploads/2013/10/hmdb51_org.rar\n",
            "Resolving serre-lab.clps.brown.edu (serre-lab.clps.brown.edu)... 128.148.254.114\n",
            "Connecting to serre-lab.clps.brown.edu (serre-lab.clps.brown.edu)|128.148.254.114|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://serre-lab.clps.brown.edu/wp-content/uploads/2013/10/hmdb51_org.rar [following]\n",
            "--2020-09-15 00:39:46--  https://serre-lab.clps.brown.edu/wp-content/uploads/2013/10/hmdb51_org.rar\n",
            "Connecting to serre-lab.clps.brown.edu (serre-lab.clps.brown.edu)|128.148.254.114|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2124008126 (2.0G)\n",
            "Saving to: â€˜hmdb51_org.rarâ€™\n",
            "\n",
            "hmdb51_org.rar      100%[===================>]   1.98G  30.1MB/s    in 66s     \n",
            "\n",
            "2020-09-15 00:40:52 (30.9 MB/s) - â€˜hmdb51_org.rarâ€™ saved [2124008126/2124008126]\n",
            "\n",
            "--2020-09-15 00:40:52--  http://serre-lab.clps.brown.edu/wp-content/uploads/2013/10/test_train_splits.rar\n",
            "Resolving serre-lab.clps.brown.edu (serre-lab.clps.brown.edu)... 128.148.254.114\n",
            "Connecting to serre-lab.clps.brown.edu (serre-lab.clps.brown.edu)|128.148.254.114|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://serre-lab.clps.brown.edu/wp-content/uploads/2013/10/test_train_splits.rar [following]\n",
            "--2020-09-15 00:40:53--  https://serre-lab.clps.brown.edu/wp-content/uploads/2013/10/test_train_splits.rar\n",
            "Connecting to serre-lab.clps.brown.edu (serre-lab.clps.brown.edu)|128.148.254.114|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 199521 (195K)\n",
            "Saving to: â€˜test_train_splits.rarâ€™\n",
            "\n",
            "test_train_splits.r 100%[===================>] 194.84K   602KB/s    in 0.3s    \n",
            "\n",
            "2020-09-15 00:40:53 (602 KB/s) - â€˜test_train_splits.rarâ€™ saved [199521/199521]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OG1Yd8Z5lpJO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import required modules ...\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "from torch.utils.data import random_split, DataLoader\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "import torchvision\n",
        "from torchvision import get_video_backend\n",
        "from torchvision.models.video import r3d_18 \n",
        "from torchvision import transforms\n",
        "import os\n",
        "from tqdm.auto import tqdm\n",
        "import numpy as np\n",
        "import time\n",
        "#import av\n",
        "import random\n",
        "#print(f\"PyAV version -- {av.__version__}\")\n",
        "\n",
        "SEED = 491\n",
        "torch.manual_seed(SEED)\n",
        "\n",
        "from collections import OrderedDict\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "#run_av_diagnostics()"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_OlXYRbZl9OF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "aa199f9a-3aba-4128-a2f3-4cb03904cb12"
      },
      "source": [
        "# Extract and organize video data..\n",
        "! mkdir -p video_data test_train_splits\n",
        "! unrar e test_train_splits.rar test_train_splits\n",
        "! rm test_train_splits.rar\n",
        "! unrar e hmdb51_org.rar \n",
        "! rm hmdb51_org.rar\n",
        "! mv *.rar video_data\n",
        "for files in os.listdir('video_data'):\n",
        "    foldername = files.split('.')[0]\n",
        "    os.system(\"mkdir -p video_data/\" + foldername)\n",
        "    os.system(\"unrar e video_data/\"+ files + \" video_data/\"+foldername)\n",
        "\n",
        "! rm video_data/*.rar "
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "UNRAR 5.50 freeware      Copyright (c) 1993-2017 Alexander Roshal\n",
            "\n",
            "\n",
            "Extracting from test_train_splits.rar\n",
            "\n",
            "Extracting  test_train_splits/brush_hair_test_split1.txt                 \b\b\b\b  0%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/brush_hair_test_split2.txt                 \b\b\b\b  1%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/brush_hair_test_split3.txt                 \b\b\b\b  1%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/cartwheel_test_split1.txt                  \b\b\b\b  2%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/cartwheel_test_split2.txt                  \b\b\b\b  2%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/cartwheel_test_split3.txt                  \b\b\b\b  3%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/catch_test_split1.txt                      \b\b\b\b  4%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/catch_test_split2.txt                      \b\b\b\b  4%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/catch_test_split3.txt                      \b\b\b\b  5%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/chew_test_split1.txt                       \b\b\b\b  5%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/chew_test_split2.txt                       \b\b\b\b  6%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/chew_test_split3.txt                       \b\b\b\b  6%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/clap_test_split1.txt                       \b\b\b\b  7%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/clap_test_split2.txt                       \b\b\b\b  7%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/clap_test_split3.txt                       \b\b\b\b  8%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/climb_stairs_test_split1.txt               \b\b\b\b  9%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/climb_stairs_test_split2.txt               \b\b\b\b 10%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/climb_stairs_test_split3.txt               \b\b\b\b 10%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/climb_test_split1.txt                      \b\b\b\b 11%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/climb_test_split2.txt                      \b\b\b\b 12%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/climb_test_split3.txt                      \b\b\b\b 12%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/dive_test_split1.txt                       \b\b\b\b 13%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/dive_test_split2.txt                       \b\b\b\b 14%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/dive_test_split3.txt                       \b\b\b\b 14%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/draw_sword_test_split1.txt                 \b\b\b\b 15%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/draw_sword_test_split2.txt                 \b\b\b\b 15%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/draw_sword_test_split3.txt                 \b\b\b\b 16%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/dribble_test_split1.txt                    \b\b\b\b 17%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/dribble_test_split2.txt                    \b\b\b\b 17%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/dribble_test_split3.txt                    \b\b\b\b 18%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/drink_test_split1.txt                      \b\b\b\b 19%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/drink_test_split2.txt                      \b\b\b\b 20%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/drink_test_split3.txt                      \b\b\b\b 20%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/eat_test_split1.txt                        \b\b\b\b 21%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/eat_test_split2.txt                        \b\b\b\b 21%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/eat_test_split3.txt                        \b\b\b\b 22%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/fall_floor_test_split1.txt                 \b\b\b\b 23%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/fall_floor_test_split2.txt                 \b\b\b\b 23%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/fall_floor_test_split3.txt                 \b\b\b\b 24%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/fencing_test_split1.txt                    \b\b\b\b 25%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/fencing_test_split2.txt                    \b\b\b\b 25%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/fencing_test_split3.txt                    \b\b\b\b 26%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/flic_flac_test_split1.txt                  \b\b\b\b 26%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/flic_flac_test_split2.txt                  \b\b\b\b 27%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/flic_flac_test_split3.txt                  \b\b\b\b 27%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/golf_test_split1.txt                       \b\b\b\b 28%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/golf_test_split2.txt                       \b\b\b\b 29%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/golf_test_split3.txt                       \b\b\b\b 29%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/handstand_test_split1.txt                  \b\b\b\b 30%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/handstand_test_split2.txt                  \b\b\b\b 31%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/handstand_test_split3.txt                  \b\b\b\b 32%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/hit_test_split1.txt                        \b\b\b\b 32%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/hit_test_split2.txt                        \b\b\b\b 33%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/hit_test_split3.txt                        \b\b\b\b 34%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/hug_test_split1.txt                        \b\b\b\b 34%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/hug_test_split2.txt                        \b\b\b\b 35%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/hug_test_split3.txt                        \b\b\b\b 35%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/jump_test_split1.txt                       \b\b\b\b 36%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/jump_test_split2.txt                       \b\b\b\b 37%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/jump_test_split3.txt                       \b\b\b\b 37%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/kick_ball_test_split1.txt                  \b\b\b\b 38%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/kick_ball_test_split2.txt                  \b\b\b\b 39%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/kick_ball_test_split3.txt                  \b\b\b\b 40%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/kick_test_split1.txt                       \b\b\b\b 40%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/kick_test_split2.txt                       \b\b\b\b 41%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/kick_test_split3.txt                       \b\b\b\b 41%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/kiss_test_split1.txt                       \b\b\b\b 42%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/kiss_test_split2.txt                       \b\b\b\b 42%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/kiss_test_split3.txt                       \b\b\b\b 42%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/laugh_test_split1.txt                      \b\b\b\b 43%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/laugh_test_split2.txt                      \b\b\b\b 43%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/laugh_test_split3.txt                      \b\b\b\b 44%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/pick_test_split1.txt                       \b\b\b\b 45%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/pick_test_split2.txt                       \b\b\b\b 45%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/pick_test_split3.txt                       \b\b\b\b 46%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/pour_test_split1.txt                       \b\b\b\b 47%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/pour_test_split2.txt                       \b\b\b\b 48%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/pour_test_split3.txt                       \b\b\b\b 48%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/pullup_test_split1.txt                     \b\b\b\b 49%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/pullup_test_split2.txt                     \b\b\b\b 49%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/pullup_test_split3.txt                     \b\b\b\b 50%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/punch_test_split1.txt                      \b\b\b\b 50%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/punch_test_split2.txt                      \b\b\b\b 51%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/punch_test_split3.txt                      \b\b\b\b 52%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/pushup_test_split1.txt                     \b\b\b\b 52%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/pushup_test_split2.txt                     \b\b\b\b 53%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/pushup_test_split3.txt                     \b\b\b\b 53%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/push_test_split1.txt                       \b\b\b\b 54%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/push_test_split2.txt                       \b\b\b\b 54%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/push_test_split3.txt                       \b\b\b\b 55%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/ride_bike_test_split1.txt                  \b\b\b\b 55%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/ride_bike_test_split2.txt                  \b\b\b\b 56%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/ride_bike_test_split3.txt                  \b\b\b\b 56%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/ride_horse_test_split1.txt                 \b\b\b\b 56%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/ride_horse_test_split2.txt                 \b\b\b\b 57%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/ride_horse_test_split3.txt                 \b\b\b\b 57%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/run_test_split1.txt                        \b\b\b\b 58%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/run_test_split2.txt                        \b\b\b\b 59%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/run_test_split3.txt                        \b\b\b\b 60%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/shake_hands_test_split1.txt                \b\b\b\b 62%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/shake_hands_test_split2.txt                \b\b\b\b 63%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/shake_hands_test_split3.txt                \b\b\b\b 64%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/shoot_ball_test_split1.txt                 \b\b\b\b 64%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/shoot_ball_test_split2.txt                 \b\b\b\b 65%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/shoot_ball_test_split3.txt                 \b\b\b\b 65%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/shoot_bow_test_split1.txt                  \b\b\b\b 66%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/shoot_bow_test_split2.txt                  \b\b\b\b 66%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/shoot_bow_test_split3.txt                  \b\b\b\b 67%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/shoot_gun_test_split1.txt                  \b\b\b\b 67%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/shoot_gun_test_split2.txt                  \b\b\b\b 67%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/shoot_gun_test_split3.txt                  \b\b\b\b 68%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/situp_test_split1.txt                      \b\b\b\b 69%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/situp_test_split2.txt                      \b\b\b\b 69%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/situp_test_split3.txt                      \b\b\b\b 70%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/sit_test_split1.txt                        \b\b\b\b 71%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/sit_test_split2.txt                        \b\b\b\b 71%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/sit_test_split3.txt                        \b\b\b\b 72%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/smile_test_split1.txt                      \b\b\b\b 73%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/smile_test_split2.txt                      \b\b\b\b 73%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/smile_test_split3.txt                      \b\b\b\b 73%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/smoke_test_split1.txt                      \b\b\b\b 74%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/smoke_test_split2.txt                      \b\b\b\b 74%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/smoke_test_split3.txt                      \b\b\b\b 75%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/somersault_test_split1.txt                 \b\b\b\b 76%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/somersault_test_split2.txt                 \b\b\b\b 76%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/somersault_test_split3.txt                 \b\b\b\b 77%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/stand_test_split1.txt                      \b\b\b\b 78%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/stand_test_split2.txt                      \b\b\b\b 79%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/stand_test_split3.txt                      \b\b\b\b 80%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/swing_baseball_test_split1.txt             \b\b\b\b 80%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/swing_baseball_test_split2.txt             \b\b\b\b 81%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/swing_baseball_test_split3.txt             \b\b\b\b 81%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/sword_exercise_test_split1.txt             \b\b\b\b 82%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/sword_exercise_test_split2.txt             \b\b\b\b 83%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/sword_exercise_test_split3.txt             \b\b\b\b 83%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/sword_test_split1.txt                      \b\b\b\b 84%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/sword_test_split2.txt                      \b\b\b\b 85%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/sword_test_split3.txt                      \b\b\b\b 86%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/talk_test_split1.txt                       \b\b\b\b 86%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/talk_test_split2.txt                       \b\b\b\b 87%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/talk_test_split3.txt                       \b\b\b\b 87%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/throw_test_split1.txt                      \b\b\b\b 88%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/throw_test_split2.txt                      \b\b\b\b 88%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/throw_test_split3.txt                      \b\b\b\b 89%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/turn_test_split1.txt                       \b\b\b\b 90%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/turn_test_split2.txt                       \b\b\b\b 91%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/turn_test_split3.txt                       \b\b\b\b 92%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/walk_test_split1.txt                       \b\b\b\b 94%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/walk_test_split2.txt                       \b\b\b\b 95%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/walk_test_split3.txt                       \b\b\b\b 97%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/wave_test_split1.txt                       \b\b\b\b 98%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/wave_test_split2.txt                       \b\b\b\b 99%\b\b\b\b\b  OK \n",
            "Extracting  test_train_splits/wave_test_split3.txt                       \b\b\b\b 99%\b\b\b\b\b  OK \n",
            "All OK\n",
            "\n",
            "UNRAR 5.50 freeware      Copyright (c) 1993-2017 Alexander Roshal\n",
            "\n",
            "\n",
            "Extracting from hmdb51_org.rar\n",
            "\n",
            "Extracting  shoot_gun.rar                                                \b\b\b\b  0%\b\b\b\b  1%\b\b\b\b\b  OK \n",
            "Extracting  sit.rar                                                      \b\b\b\b  1%\b\b\b\b  2%\b\b\b\b  3%\b\b\b\b\b  OK \n",
            "Extracting  situp.rar                                                    \b\b\b\b  3%\b\b\b\b  4%\b\b\b\b\b  OK \n",
            "Extracting  smile.rar                                                    \b\b\b\b  4%\b\b\b\b  5%\b\b\b\b\b  OK \n",
            "Extracting  smoke.rar                                                    \b\b\b\b  5%\b\b\b\b  6%\b\b\b\b  7%\b\b\b\b\b  OK \n",
            "Extracting  somersault.rar                                               \b\b\b\b  7%\b\b\b\b  8%\b\b\b\b  9%\b\b\b\b\b  OK \n",
            "Extracting  stand.rar                                                    \b\b\b\b  9%\b\b\b\b 10%\b\b\b\b 11%\b\b\b\b\b  OK \n",
            "Extracting  swing_baseball.rar                                           \b\b\b\b 11%\b\b\b\b 12%\b\b\b\b 13%\b\b\b\b\b  OK \n",
            "Extracting  sword.rar                                                    \b\b\b\b 13%\b\b\b\b 14%\b\b\b\b 15%\b\b\b\b\b  OK \n",
            "Extracting  sword_exercise.rar                                           \b\b\b\b 15%\b\b\b\b 16%\b\b\b\b 17%\b\b\b\b\b  OK \n",
            "Extracting  talk.rar                                                     \b\b\b\b 17%\b\b\b\b 18%\b\b\b\b 19%\b\b\b\b\b  OK \n",
            "Extracting  throw.rar                                                    \b\b\b\b 19%\b\b\b\b 20%\b\b\b\b 21%\b\b\b\b\b  OK \n",
            "Extracting  turn.rar                                                     \b\b\b\b 21%\b\b\b\b 22%\b\b\b\b 23%\b\b\b\b\b  OK \n",
            "Extracting  walk.rar                                                     \b\b\b\b 23%\b\b\b\b 24%\b\b\b\b 25%\b\b\b\b 26%\b\b\b\b 27%\b\b\b\b 28%\b\b\b\b 29%\b\b\b\b 30%\b\b\b\b 31%\b\b\b\b 32%\b\b\b\b\b  OK \n",
            "Extracting  wave.rar                                                     \b\b\b\b 32%\b\b\b\b 33%\b\b\b\b\b  OK \n",
            "Extracting  brush_hair.rar                                               \b\b\b\b 33%\b\b\b\b 34%\b\b\b\b 35%\b\b\b\b 36%\b\b\b\b 37%\b\b\b\b\b  OK \n",
            "Extracting  cartwheel.rar                                                \b\b\b\b 37%\b\b\b\b 38%\b\b\b\b 39%\b\b\b\b\b  OK \n",
            "Extracting  catch.rar                                                    \b\b\b\b 39%\b\b\b\b\b  OK \n",
            "Extracting  chew.rar                                                     \b\b\b\b 39%\b\b\b\b 40%\b\b\b\b 41%\b\b\b\b\b  OK \n",
            "Extracting  clap.rar                                                     \b\b\b\b 41%\b\b\b\b 42%\b\b\b\b 43%\b\b\b\b\b  OK \n",
            "Extracting  climb.rar                                                    \b\b\b\b 43%\b\b\b\b 44%\b\b\b\b 45%\b\b\b\b\b  OK \n",
            "Extracting  climb_stairs.rar                                             \b\b\b\b 45%\b\b\b\b 46%\b\b\b\b 47%\b\b\b\b\b  OK \n",
            "Extracting  dive.rar                                                     \b\b\b\b 47%\b\b\b\b 48%\b\b\b\b\b  OK \n",
            "Extracting  draw_sword.rar                                               \b\b\b\b 49%\b\b\b\b 50%\b\b\b\b\b  OK \n",
            "Extracting  dribble.rar                                                  \b\b\b\b 50%\b\b\b\b 51%\b\b\b\b 52%\b\b\b\b\b  OK \n",
            "Extracting  drink.rar                                                    \b\b\b\b 52%\b\b\b\b 53%\b\b\b\b 54%\b\b\b\b\b  OK \n",
            "Extracting  eat.rar                                                      \b\b\b\b 54%\b\b\b\b 55%\b\b\b\b\b  OK \n",
            "Extracting  fall_floor.rar                                               \b\b\b\b 55%\b\b\b\b 56%\b\b\b\b 57%\b\b\b\b\b  OK \n",
            "Extracting  fencing.rar                                                  \b\b\b\b 57%\b\b\b\b 58%\b\b\b\b\b  OK \n",
            "Extracting  flic_flac.rar                                                \b\b\b\b 58%\b\b\b\b 59%\b\b\b\b 60%\b\b\b\b\b  OK \n",
            "Extracting  golf.rar                                                     \b\b\b\b 60%\b\b\b\b 61%\b\b\b\b\b  OK \n",
            "Extracting  handstand.rar                                                \b\b\b\b 61%\b\b\b\b 62%\b\b\b\b 63%\b\b\b\b\b  OK \n",
            "Extracting  hit.rar                                                      \b\b\b\b 63%\b\b\b\b 64%\b\b\b\b\b  OK \n",
            "Extracting  hug.rar                                                      \b\b\b\b 64%\b\b\b\b 65%\b\b\b\b\b  OK \n",
            "Extracting  jump.rar                                                     \b\b\b\b 65%\b\b\b\b 66%\b\b\b\b 67%\b\b\b\b\b  OK \n",
            "Extracting  kick.rar                                                     \b\b\b\b 67%\b\b\b\b 68%\b\b\b\b\b  OK \n",
            "Extracting  kick_ball.rar                                                \b\b\b\b 68%\b\b\b\b 69%\b\b\b\b\b  OK \n",
            "Extracting  kiss.rar                                                     \b\b\b\b 69%\b\b\b\b 70%\b\b\b\b 71%\b\b\b\b\b  OK \n",
            "Extracting  laugh.rar                                                    \b\b\b\b 71%\b\b\b\b 72%\b\b\b\b 73%\b\b\b\b 74%\b\b\b\b 75%\b\b\b\b\b  OK \n",
            "Extracting  pick.rar                                                     \b\b\b\b 75%\b\b\b\b 76%\b\b\b\b\b  OK \n",
            "Extracting  pour.rar                                                     \b\b\b\b 76%\b\b\b\b 77%\b\b\b\b 78%\b\b\b\b\b  OK \n",
            "Extracting  pullup.rar                                                   \b\b\b\b 78%\b\b\b\b 79%\b\b\b\b 80%\b\b\b\b\b  OK \n",
            "Extracting  punch.rar                                                    \b\b\b\b 80%\b\b\b\b 81%\b\b\b\b\b  OK \n",
            "Extracting  push.rar                                                     \b\b\b\b 81%\b\b\b\b 82%\b\b\b\b 83%\b\b\b\b\b  OK \n",
            "Extracting  pushup.rar                                                   \b\b\b\b 83%\b\b\b\b 84%\b\b\b\b\b  OK \n",
            "Extracting  ride_bike.rar                                                \b\b\b\b 84%\b\b\b\b 85%\b\b\b\b 86%\b\b\b\b\b  OK \n",
            "Extracting  ride_horse.rar                                               \b\b\b\b 86%\b\b\b\b 87%\b\b\b\b 88%\b\b\b\b 89%\b\b\b\b\b  OK \n",
            "Extracting  run.rar                                                      \b\b\b\b 89%\b\b\b\b 90%\b\b\b\b 91%\b\b\b\b 92%\b\b\b\b\b  OK \n",
            "Extracting  shake_hands.rar                                              \b\b\b\b 92%\b\b\b\b 93%\b\b\b\b 94%\b\b\b\b 95%\b\b\b\b\b  OK \n",
            "Extracting  shoot_ball.rar                                               \b\b\b\b 95%\b\b\b\b 96%\b\b\b\b\b  OK \n",
            "Extracting  shoot_bow.rar                                                \b\b\b\b 96%\b\b\b\b 97%\b\b\b\b 98%\b\b\b\b 99%\b\b\b\b\b  OK \n",
            "All OK\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8R5uv0YymAXk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "715a4c26-006d-4ecf-de2a-ae2b6edd1937"
      },
      "source": [
        "# diagnostics for PyAV installation. For now version 6.2.0 works \n",
        "def run_av_diagnostics():\n",
        "    import av\n",
        "    av.open(\"video_data/brush_hair/Aussie_Brunette_Brushing_Hair_II_brush_hair_u_nm_np1_ba_goo_4.avi\")\n",
        "    print(get_video_backend())\n",
        "    av.logging.set_level(av.logging.ERROR)\n",
        "    if not hasattr(av.video.frame.VideoFrame, 'pict_type'):\n",
        "      print(\"Nah\")\n",
        "\n",
        "run_av_diagnostics()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "pyav\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HE1Qd_RFmJEd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "outputId": "d4c2abd5-982f-4441-dc2b-50a76fb392f5"
      },
      "source": [
        "# memory footprint support libraries/code\n",
        "!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
        "!pip install gputil\n",
        "!pip install psutil\n",
        "!pip install humanize\n",
        "\n",
        "import psutil\n",
        "import humanize\n",
        "import os\n",
        "import GPUtil as GPU\n",
        "\n",
        "GPUs = GPU.getGPUs()\n",
        "# XXX: only one GPU on Colab and isnâ€™t guaranteed\n",
        "gpu = GPUs[0]\n",
        "def printm():\n",
        "    process = psutil.Process(os.getpid())\n",
        "    print(\"Gen RAM Free: \" + humanize.naturalsize(psutil.virtual_memory().available), \" |     Proc size: \" + humanize.naturalsize(process.memory_info().rss))\n",
        "    print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total     {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n",
        "printm()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting gputil\n",
            "  Downloading https://files.pythonhosted.org/packages/ed/0e/5c61eedde9f6c87713e89d794f01e378cfd9565847d4576fa627d758c554/GPUtil-1.4.0.tar.gz\n",
            "Building wheels for collected packages: gputil\n",
            "  Building wheel for gputil (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gputil: filename=GPUtil-1.4.0-cp36-none-any.whl size=7411 sha256=0a8866adf75b2c953b3d07ac8db1c93e576a6accb8135d541278a36dd0f9af54\n",
            "  Stored in directory: /root/.cache/pip/wheels/3d/77/07/80562de4bb0786e5ea186911a2c831fdd0018bda69beab71fd\n",
            "Successfully built gputil\n",
            "Installing collected packages: gputil\n",
            "Successfully installed gputil-1.4.0\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.6/dist-packages (5.4.8)\n",
            "Requirement already satisfied: humanize in /usr/local/lib/python3.6/dist-packages (0.5.1)\n",
            "Gen RAM Free: 12.7 GB  |     Proc size: 281.6 MB\n",
            "GPU RAM Free: 15079MB | Used: 0MB | Util   0% | Total     15079MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "adI8h2W3KP1a",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 209
        },
        "outputId": "c631bba0-a4c9-4e2a-e1cd-bb0eca9a90e1"
      },
      "source": [
        "# download video transformation functions from below link\n",
        "! wget https://raw.githubusercontent.com/pytorch/vision/6de158c473b83cf43344a0651d7c01128c7850e6/references/video_classification/transforms.py\n",
        "import transforms as T"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-09-15 00:42:28--  https://raw.githubusercontent.com/pytorch/vision/6de158c473b83cf43344a0651d7c01128c7850e6/references/video_classification/transforms.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3102 (3.0K) [text/plain]\n",
            "Saving to: â€˜transforms.pyâ€™\n",
            "\n",
            "transforms.py       100%[===================>]   3.03K  --.-KB/s    in 0s      \n",
            "\n",
            "2020-09-15 00:42:29 (66.7 MB/s) - â€˜transforms.pyâ€™ saved [3102/3102]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1tr86vGYyrwV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch\n",
        "\n",
        "\n",
        "class ConvLSTMCell(nn.Module):\n",
        "\n",
        "    def __init__(self, input_dim, hidden_dim, kernel_size, bias):\n",
        "        \"\"\"\n",
        "        Initialize ConvLSTM cell.\n",
        "        Parameters\n",
        "        ----------\n",
        "        input_dim: int\n",
        "            Number of channels of input tensor.\n",
        "        hidden_dim: int\n",
        "            Number of channels of hidden state.\n",
        "        kernel_size: (int, int)\n",
        "            Size of the convolutional kernel.\n",
        "        bias: bool\n",
        "            Whether or not to add the bias.\n",
        "        \"\"\"\n",
        "\n",
        "        super(ConvLSTMCell, self).__init__()\n",
        "\n",
        "        self.input_dim = input_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "\n",
        "        self.kernel_size = kernel_size\n",
        "        self.padding = kernel_size[0] // 2, kernel_size[1] // 2\n",
        "        self.bias = bias\n",
        "\n",
        "        self.conv = nn.Conv2d(in_channels=self.input_dim + self.hidden_dim,\n",
        "                              out_channels=4 * self.hidden_dim,\n",
        "                              kernel_size=self.kernel_size,\n",
        "                              padding=self.padding,\n",
        "                              bias=self.bias)\n",
        "\n",
        "    def forward(self, input_tensor, cur_state):\n",
        "        h_cur, c_cur = cur_state\n",
        "\n",
        "        combined = torch.cat([input_tensor, h_cur], dim=1)  # concatenate along channel axis\n",
        "\n",
        "        combined_conv = self.conv(combined)\n",
        "        cc_i, cc_f, cc_o, cc_g = torch.split(combined_conv, self.hidden_dim, dim=1)\n",
        "        i = torch.sigmoid(cc_i)\n",
        "        f = torch.sigmoid(cc_f)\n",
        "        o = torch.sigmoid(cc_o)\n",
        "        g = torch.tanh(cc_g)\n",
        "\n",
        "        c_next = f * c_cur + i * g\n",
        "        h_next = o * torch.tanh(c_next)\n",
        "\n",
        "        return h_next, c_next\n",
        "\n",
        "    def init_hidden(self, batch_size, image_size):\n",
        "        height, width = image_size\n",
        "        return (torch.zeros(batch_size, self.hidden_dim, height, width, device=self.conv.weight.device),\n",
        "                torch.zeros(batch_size, self.hidden_dim, height, width, device=self.conv.weight.device))\n",
        "\n",
        "\n",
        "class ConvLSTM(nn.Module):\n",
        "\n",
        "    \"\"\"\n",
        "    Parameters:\n",
        "        input_dim: Number of channels in input\n",
        "        hidden_dim: Number of hidden channels\n",
        "        kernel_size: Size of kernel in convolutions\n",
        "        num_layers: Number of LSTM layers stacked on each other\n",
        "        batch_first: Whether or not dimension 0 is the batch or not\n",
        "        bias: Bias or no bias in Convolution\n",
        "        return_all_layers: Return the list of computations for all layers\n",
        "        Note: Will do same padding.\n",
        "    Input:\n",
        "        A tensor of size B, T, C, H, W or T, B, C, H, W\n",
        "    Output:\n",
        "        A tuple of two lists of length num_layers (or length 1 if return_all_layers is False).\n",
        "            0 - layer_output_list is the list of lists of length T of each output\n",
        "            1 - last_state_list is the list of last states\n",
        "                    each element of the list is a tuple (h, c) for hidden state and memory\n",
        "    Example:\n",
        "        >> x = torch.rand((32, 10, 64, 128, 128))\n",
        "        >> convlstm = ConvLSTM(64, 16, 3, 1, True, True, False)\n",
        "        >> _, last_states = convlstm(x)\n",
        "        >> h = last_states[0][0]  # 0 for layer index, 0 for h index\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, input_dim, hidden_dim, kernel_size, num_layers,\n",
        "                 batch_first=False, bias=True, return_all_layers=False):\n",
        "        super(ConvLSTM, self).__init__()\n",
        "\n",
        "        self._check_kernel_size_consistency(kernel_size)\n",
        "\n",
        "        # Make sure that both `kernel_size` and `hidden_dim` are lists having len == num_layers\n",
        "        kernel_size = self._extend_for_multilayer(kernel_size, num_layers)\n",
        "        hidden_dim = self._extend_for_multilayer(hidden_dim, num_layers)\n",
        "        if not len(kernel_size) == len(hidden_dim) == num_layers:\n",
        "            raise ValueError('Inconsistent list length.')\n",
        "\n",
        "        self.input_dim = input_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.kernel_size = kernel_size\n",
        "        self.num_layers = num_layers\n",
        "        self.batch_first = batch_first\n",
        "        self.bias = bias\n",
        "        self.return_all_layers = return_all_layers\n",
        "\n",
        "        cell_list = []\n",
        "        for i in range(0, self.num_layers):\n",
        "            cur_input_dim = self.input_dim if i == 0 else self.hidden_dim[i - 1]\n",
        "\n",
        "            cell_list.append(ConvLSTMCell(input_dim=cur_input_dim,\n",
        "                                          hidden_dim=self.hidden_dim[i],\n",
        "                                          kernel_size=self.kernel_size[i],\n",
        "                                          bias=self.bias))\n",
        "\n",
        "        self.cell_list = nn.ModuleList(cell_list)\n",
        "\n",
        "    def forward(self, input_tensor, hidden_state=None):\n",
        "        \"\"\"\n",
        "        Parameters\n",
        "        ----------\n",
        "        input_tensor: todo\n",
        "            5-D Tensor either of shape (t, b, c, h, w) or (b, t, c, h, w)\n",
        "        hidden_state: todo\n",
        "            None. todo implement stateful\n",
        "        Returns\n",
        "        -------\n",
        "        last_state_list, layer_output\n",
        "        \"\"\"\n",
        "        if not self.batch_first:\n",
        "            # (t, b, c, h, w) -> (b, t, c, h, w)\n",
        "            input_tensor = input_tensor.permute(1, 0, 2, 3, 4)\n",
        "\n",
        "        b, _, _, h, w = input_tensor.size()\n",
        "\n",
        "        # Implement stateful ConvLSTM\n",
        "        if hidden_state is not None:\n",
        "            raise NotImplementedError()\n",
        "        else:\n",
        "            # Since the init is done in forward. Can send image size here\n",
        "            hidden_state = self._init_hidden(batch_size=b,\n",
        "                                             image_size=(h, w))\n",
        "\n",
        "        layer_output_list = []\n",
        "        last_state_list = []\n",
        "\n",
        "        seq_len = input_tensor.size(1)\n",
        "        cur_layer_input = input_tensor\n",
        "\n",
        "        for layer_idx in range(self.num_layers):\n",
        "\n",
        "            h, c = hidden_state[layer_idx]\n",
        "            output_inner = []\n",
        "            for t in range(seq_len):\n",
        "                h, c = self.cell_list[layer_idx](input_tensor=cur_layer_input[:, t, :, :, :],\n",
        "                                                 cur_state=[h, c])\n",
        "                output_inner.append(h)\n",
        "\n",
        "            layer_output = torch.stack(output_inner, dim=1)\n",
        "            cur_layer_input = layer_output\n",
        "\n",
        "            layer_output_list.append(layer_output)\n",
        "            last_state_list.append([h, c])\n",
        "\n",
        "        if not self.return_all_layers:\n",
        "            layer_output_list = layer_output_list[-1:]\n",
        "            last_state_list = last_state_list[-1:]\n",
        "\n",
        "        return layer_output_list, last_state_list\n",
        "\n",
        "    def _init_hidden(self, batch_size, image_size):\n",
        "        init_states = []\n",
        "        for i in range(self.num_layers):\n",
        "            init_states.append(self.cell_list[i].init_hidden(batch_size, image_size))\n",
        "        return init_states\n",
        "\n",
        "    @staticmethod\n",
        "    def _check_kernel_size_consistency(kernel_size):\n",
        "        if not (isinstance(kernel_size, tuple) or\n",
        "                (isinstance(kernel_size, list) and all([isinstance(elem, tuple) for elem in kernel_size]))):\n",
        "            raise ValueError('`kernel_size` must be tuple or list of tuples')\n",
        "\n",
        "    @staticmethod\n",
        "    def _extend_for_multilayer(param, num_layers):\n",
        "        if not isinstance(param, list):\n",
        "            param = [param] * num_layers\n",
        "        return param"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JfzeiPkfmOK_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "dc1261d5-9aad-47fc-b6a0-d89d02689a07"
      },
      "source": [
        "# set up a sample pytorch class to check if it works\n",
        "class Model(nn.Module):\n",
        "  def __init__(self):\n",
        "      super(Model, self).__init__()\n",
        "      self.base_model = nn.Sequential(*list(r3d_18(pretrained=False).children())[:-1])\n",
        "      self.fc1 = nn.Linear(512, 51)\n",
        "\n",
        "  def forward(self, x):\n",
        "      out = self.base_model(x).squeeze(4).squeeze(3).squeeze(2)\n",
        "      print(\"size after pretrained model \", out.size())\n",
        "      out = torch.log_softmax(self.fc1(out), dim=1)\n",
        "      return out\n",
        "\n",
        "check = Model().cuda()\n",
        "out = check(torch.randn(16, 3 , 8, 112,112).cuda())\n",
        "out.size()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "size after pretrained model  torch.Size([16, 512])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([16, 51])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rmia3p2SZCkS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class AverageMeter(object):\n",
        "    \"\"\"\n",
        "    Computes and stores the average and current value\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.val = 0\n",
        "        self.avg = 0\n",
        "        self.sum = 0\n",
        "        self.count = 0\n",
        "\n",
        "    def update(self, val, n=1):\n",
        "        self.val = val\n",
        "        self.sum += val * n\n",
        "        self.count += n\n",
        "        self.avg = self.sum / self.count\n",
        "\n",
        "    def update_acc(self, val, n=1):\n",
        "        self.val = val/n\n",
        "        self.sum += val\n",
        "        self.count += n\n",
        "        self.avg = self.sum / self.count"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TLv5orDEme8z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define model using PyTorch\n",
        "class VideoRecog_Model(nn.Module):\n",
        "  def __init__(self):\n",
        "      super(VideoRecog_Model, self).__init__()\n",
        "      self.base_model = nn.Sequential(*list(r3d_18(pretrained=True).children())[:-1])\n",
        "      self.fc1 = nn.Linear(512, 51)\n",
        "      self.fc2 = nn.Linear(51, 51) \n",
        "      self.dropout = nn.Dropout2d(0.3) \n",
        "\n",
        "  def forward(self, x):\n",
        "      out = self.base_model(x).squeeze(4).squeeze(3).squeeze(2) # output of base model is bs x 512 x 1 x 1 x 1\n",
        "      out = F.relu(self.fc1(out)) \n",
        "      out = self.dropout(out) \n",
        "      out = torch.log_softmax(self.fc2(out), dim=1)\n",
        "      return out"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AOULzxhDmzZy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(config, model, loader, optimizer, epoch):\n",
        "    model.train()\n",
        "    config = {}\n",
        "    config['log_interval'] = 100\n",
        "    correct = 0\n",
        "    total_loss = 0.0\n",
        "    flag = 0\n",
        "    Loss, Acc = AverageMeter(), AverageMeter()\n",
        "    start = time.time()\n",
        "    for batch_id, data in enumerate(loader):\n",
        "        data, target = data[0], data[-1]\n",
        "        # print(\"here\")\n",
        "\n",
        "        if torch.cuda.is_available():\n",
        "           data = data.cuda()\n",
        "           target = target.cuda()\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        output,hidden = model(data)\n",
        "        loss = nn.CrossEntropyLoss()(output, target)\n",
        "        total_loss += loss.item()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        Loss.update(loss.item(), data.size(0))\n",
        "\n",
        "        pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
        "        num_corrects = pred.eq(target.view_as(pred)).sum().item()\n",
        "        correct += num_corrects\n",
        "\n",
        "        Acc.update_acc(num_corrects, data.size(0))\n",
        "\n",
        "        if flag!= 0 and batch_id%config['log_interval'] == 0:\n",
        "           print('Train Epoch: {} Batch [{}/{} ({:.0f}%)]\\tLoss: {:.6f} Accuracy: {}/{} ({:.0f})%'.format(\n",
        "                epoch, batch_id * len(data), len(loader.dataset),\n",
        "                100. * batch_id / len(loader), Loss.avg, correct, Acc.count, 100. * Acc.avg))\n",
        "        flag = 1\n",
        "\n",
        "    #total_loss /= len(loader.dataset) \n",
        "    print('Train Epoch: {} Average Loss: {:.6f} Average Accuracy: {}/{} ({:.0f})%'.format(\n",
        "         epoch, Loss.avg, correct, Acc.count, 100. * Acc.avg ))\n",
        "    print(f\"Takes {time.time() - start}\")"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oj_n6CR4rJ_8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test(config, model, loader, text='Validation'):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total_loss = 0.0\n",
        "    Loss, Acc = AverageMeter(), AverageMeter()\n",
        "    with torch.no_grad():\n",
        "         for batch_id, data in enumerate(loader):\n",
        "             data, target = data[0], data[-1]\n",
        "\n",
        "             if torch.cuda.is_available():\n",
        "                data = data.cuda()\n",
        "                target = target.cuda()\n",
        "\n",
        "             output = model(data)\n",
        "             loss = F.nll_loss(output, target)\n",
        "             total_loss += loss.item()\n",
        "\n",
        "             Loss.update(loss.item(), data.size(0))\n",
        "\n",
        "             pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
        "             num_corrects = pred.eq(target.view_as(pred)).sum().item()\n",
        "             correct += num_corrects\n",
        "\n",
        "             Acc.update_acc(num_corrects, data.size(0))\n",
        "           \n",
        "    total_loss /= len(loader.dataset)\n",
        "    print(text + ' Average Loss: {:.6f} Average Accuracy: {}/{} ({:.0f})%'.format(\n",
        "         Loss.avg, correct, Acc.count , 100. * Acc.avg ))"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5-QY8fYGmmkt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168,
          "referenced_widgets": [
            "1b4b786d8f1d4ccf90bef776ec7de493",
            "43caf05ca8844aafb3f2e13a772f100a",
            "ac1c8a5f31724bd7ababafe6bfbe0a18",
            "b15ea291687f4fcc85efc66661e15699",
            "8aed90bbdd514c23a8bdc55473170a37",
            "f361fb2acae04ab7b0853d31bbd6808d",
            "f2dacdc81daa44fd8798b7ded497c665",
            "236f0af443ad42ab8020276058fc938f",
            "ed31b429fab949de993d7ff902181b21",
            "a1c86ea4f28b45bb865feda301f1444f",
            "2d65a4ff56bf487b936551769023b271",
            "1e0c1a9c619e478bb5656466e3f97ca5",
            "ed8411a80bad41f7ae85186d309562ba",
            "2831b3a56cb240f48860674e39a38b1d",
            "ce0aa727b8e84391b11092ee26120287",
            "1d1e405b8f2b441e80e7762f7da8d5d1"
          ]
        },
        "outputId": "262494b4-a875-49e1-b2f8-c8b258b6920e"
      },
      "source": [
        "# Datasets and Dataloaders for model training ..\n",
        "\n",
        "val_split = 0.05\n",
        "num_frames = 16 # 16\n",
        "clip_steps = 50\n",
        "num_workers = 8\n",
        "pin_memory = True\n",
        "train_tfms = torchvision.transforms.Compose([\n",
        "                                 T.ToFloatTensorInZeroOne(),\n",
        "                                 T.Resize((128, 171)),\n",
        "                                 T.RandomHorizontalFlip(),\n",
        "                                 T.Normalize(mean=[0.43216, 0.394666, 0.37645], std=[0.22803, 0.22145, 0.216989]),\n",
        "                                 T.RandomCrop((112, 112))\n",
        "                               ])  \n",
        "test_tfms =  torchvision.transforms.Compose([\n",
        "                                             T.ToFloatTensorInZeroOne(),\n",
        "                                             T.Resize((128, 171)),\n",
        "                                             T.Normalize(mean=[0.43216, 0.394666, 0.37645], std=[0.22803, 0.22145, 0.216989]),\n",
        "                                             T.CenterCrop((112, 112))\n",
        "                                             ])\n",
        "hmdb51_train = torchvision.datasets.HMDB51('video_data/', 'test_train_splits/', num_frames,\n",
        "                                                step_between_clips = clip_steps, fold=1, train=True,\n",
        "                                                transform=train_tfms, num_workers=num_workers)\n",
        "\n",
        "\n",
        "hmdb51_test = torchvision.datasets.HMDB51('video_data/', 'test_train_splits/', num_frames,\n",
        "                                                step_between_clips = clip_steps, fold=1, train=False,\n",
        "                                                transform=test_tfms, num_workers=num_workers)\n",
        "      \n",
        "total_train_samples = len(hmdb51_train)\n",
        "total_val_samples = round(val_split * total_train_samples)\n",
        "\n",
        "print(f\"number of train samples {total_train_samples}\")\n",
        "print(f\"number of validation samples {total_val_samples}\")\n",
        "print(f\"number of test samples {len(hmdb51_test)}\")\n"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1b4b786d8f1d4ccf90bef776ec7de493",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=423.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ed31b429fab949de993d7ff902181b21",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=423.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "number of train samples 7754\n",
            "number of validation samples 388\n",
            "number of test samples 3234\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eCiGrETSbZTq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        },
        "outputId": "eedabcd2-dd5e-4fed-efa8-479562a0209e"
      },
      "source": [
        ""
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-39-395a7441f620>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_tfms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: 'Compose' object has no attribute 'shape'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BrfX3Rk0sTcR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "outputId": "9f42734e-1952-4e3b-a3d6-5c0522c5133c"
      },
      "source": [
        "bs = 4\n",
        "lr = 1e-2\n",
        "gamma = 0.7\n",
        "total_epochs = 10\n",
        "config = {}\n",
        "num_workers = 0\n",
        "\n",
        "kwargs = {'num_workers':num_workers, 'pin_memory':True} if torch.cuda.is_available() else {'num_workers':num_workers}\n",
        "#kwargs = {'num_workers':num_workers}\n",
        "#kwargs = {}\n",
        "\n",
        "hmdb51_train_v1, hmdb51_val_v1 = random_split(hmdb51_train, [total_train_samples - total_val_samples,\n",
        "                                                                       total_val_samples])\n",
        "\n",
        "#hmdb51_train_v1.video_clips.compute_clips(16, 1, frame_rate=30)\n",
        "#hmdb51_val_v1.video_clips.compute_clips(16, 1, frame_rate=30)\n",
        "#hmdb51_test.video_clips.compute_clips(16, 1, frame_rate=30)\n",
        "\n",
        "#train_sampler = RandomClipSampler(hmdb51_train_v1.video_clips, 5)\n",
        "#test_sampler = UniformClipSampler(hmdb51_test.video_clips, 5)\n",
        "  \n",
        "train_loader = DataLoader(hmdb51_train_v1, batch_size=bs, shuffle=True, **kwargs)\n",
        "val_loader   = DataLoader(hmdb51_val_v1, batch_size=bs, shuffle=True, **kwargs)\n",
        "test_loader  = DataLoader(hmdb51_test, batch_size=bs, shuffle=False, **kwargs)\n",
        "\n",
        "model = ConvLSTM(16,51,(3,3),1)\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "   model = model.cuda()\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "scheduler = StepLR(optimizer, step_size=1, gamma=gamma)\n",
        "\n",
        "print(\"Launching Action Recognition Model training\")\n",
        "for epoch in range(1, total_epochs + 1):\n",
        "    train(config, model, train_loader, optimizer, epoch)\n",
        "    test(config, model, val_loader, text=\"Validation\")\n",
        "    scheduler.step()\n",
        "\n",
        "test(config, model, test_loader, text=\"Test\")"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Launching Action Recognition Model training\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-50-9df01e02d731>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Launching Action Recognition Model training\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_epochs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m     \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Validation\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0mscheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-49-0be159af8c6e>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(config, model, loader, optimizer, epoch)\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0mtotal_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    946\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m         return F.cross_entropy(input, target, weight=self.weight,\n\u001b[0;32m--> 948\u001b[0;31m                                ignore_index=self.ignore_index, reduction=self.reduction)\n\u001b[0m\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[1;32m   2420\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2421\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2422\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2423\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2424\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlog_softmax\u001b[0;34m(input, dim, _stacklevel, dtype)\u001b[0m\n\u001b[1;32m   1589\u001b[0m         \u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_softmax_dim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'log_softmax'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_stacklevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1590\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1591\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1592\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1593\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'log_softmax'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vlfkKuc-k-ZV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e426514d-34f2-4dbb-cc36-60eeafec2d86"
      },
      "source": [
        "torch.cuda.is_available()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b3HHLAZa15nI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in DataLoader(hmdb51_train, batch_size=4):\n",
        "    break"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}