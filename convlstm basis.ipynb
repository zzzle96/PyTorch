{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled17.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMojkwfy9Nv8qOt10UoJHfq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zzzle96/PyTorch/blob/master/convlstm%20basis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gghYIktVFQVw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 717
        },
        "outputId": "92cfc618-a8f4-4ba5-dda0-3ebbde5e515d"
      },
      "source": [
        "# Install dependencies for video module in pytorch to work\n",
        "! apt-get install libavformat-dev libavdevice-dev\n",
        "! pip install av==6.2.0"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "libavformat-dev is already the newest version (7:3.4.8-0ubuntu0.2).\n",
            "libavformat-dev set to manually installed.\n",
            "The following additional packages will be installed:\n",
            "  libavfilter-dev libpostproc-dev\n",
            "The following NEW packages will be installed:\n",
            "  libavdevice-dev libavfilter-dev libpostproc-dev\n",
            "0 upgraded, 3 newly installed, 0 to remove and 11 not upgraded.\n",
            "Need to get 1,154 kB of archives.\n",
            "After this operation, 5,444 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 libpostproc-dev amd64 7:3.4.8-0ubuntu0.2 [51.0 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 libavfilter-dev amd64 7:3.4.8-0ubuntu0.2 [1,016 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 libavdevice-dev amd64 7:3.4.8-0ubuntu0.2 [87.2 kB]\n",
            "Fetched 1,154 kB in 1s (799 kB/s)\n",
            "Selecting previously unselected package libpostproc-dev:amd64.\n",
            "(Reading database ... 144676 files and directories currently installed.)\n",
            "Preparing to unpack .../libpostproc-dev_7%3a3.4.8-0ubuntu0.2_amd64.deb ...\n",
            "Unpacking libpostproc-dev:amd64 (7:3.4.8-0ubuntu0.2) ...\n",
            "Selecting previously unselected package libavfilter-dev:amd64.\n",
            "Preparing to unpack .../libavfilter-dev_7%3a3.4.8-0ubuntu0.2_amd64.deb ...\n",
            "Unpacking libavfilter-dev:amd64 (7:3.4.8-0ubuntu0.2) ...\n",
            "Selecting previously unselected package libavdevice-dev:amd64.\n",
            "Preparing to unpack .../libavdevice-dev_7%3a3.4.8-0ubuntu0.2_amd64.deb ...\n",
            "Unpacking libavdevice-dev:amd64 (7:3.4.8-0ubuntu0.2) ...\n",
            "Setting up libpostproc-dev:amd64 (7:3.4.8-0ubuntu0.2) ...\n",
            "Setting up libavfilter-dev:amd64 (7:3.4.8-0ubuntu0.2) ...\n",
            "Setting up libavdevice-dev:amd64 (7:3.4.8-0ubuntu0.2) ...\n",
            "Collecting av==6.2.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/84/77/0be0fdaa3b7912c184705a4545ae6f1e9e47ab9e3834a3ef5caf2d7ca1e7/av-6.2.0.tar.gz (2.0MB)\n",
            "\u001b[K     |████████████████████████████████| 2.0MB 4.6MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: av\n",
            "av\n",
            "  Building wheel for av (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for av: filename=av-6.2.0-cp36-cp36m-linux_x86_64.whl size=5002920 sha256=7adcb7cf5664ecb58b9d69a6ed169fe650884c7ec5f8a8388adf73ebbc06c04e\n",
            "  Stored in directory: /root/.cache/pip/wheels/2f/c1/b2/05e83d944cde5df317e4542082d67756ec4224c7885aee2d66\n",
            "Successfully built av\n",
            "Installing collected packages: av\n",
            "Successfully installed av-6.2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G16vQpeMFQO_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "outputId": "eb9529fa-8568-4c4d-fac3-db30ee855583"
      },
      "source": [
        "# Download HMDB51 data and splits from serre lab website\n",
        "! wget http://serre-lab.clps.brown.edu/wp-content/uploads/2013/10/hmdb51_org.rar\n",
        "! wget http://serre-lab.clps.brown.edu/wp-content/uploads/2013/10/test_train_splits.rar"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-09-20 05:59:05--  http://serre-lab.clps.brown.edu/wp-content/uploads/2013/10/hmdb51_org.rar\n",
            "Resolving serre-lab.clps.brown.edu (serre-lab.clps.brown.edu)... 128.148.254.114\n",
            "Connecting to serre-lab.clps.brown.edu (serre-lab.clps.brown.edu)|128.148.254.114|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://serre-lab.clps.brown.edu/wp-content/uploads/2013/10/hmdb51_org.rar [following]\n",
            "--2020-09-20 05:59:05--  https://serre-lab.clps.brown.edu/wp-content/uploads/2013/10/hmdb51_org.rar\n",
            "Connecting to serre-lab.clps.brown.edu (serre-lab.clps.brown.edu)|128.148.254.114|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2124008126 (2.0G)\n",
            "Saving to: ‘hmdb51_org.rar’\n",
            "\n",
            "hmdb51_org.rar      100%[===================>]   1.98G  27.5MB/s    in 59s     \n",
            "\n",
            "2020-09-20 06:00:04 (34.4 MB/s) - ‘hmdb51_org.rar’ saved [2124008126/2124008126]\n",
            "\n",
            "--2020-09-20 06:00:04--  http://serre-lab.clps.brown.edu/wp-content/uploads/2013/10/test_train_splits.rar\n",
            "Resolving serre-lab.clps.brown.edu (serre-lab.clps.brown.edu)... 128.148.254.114\n",
            "Connecting to serre-lab.clps.brown.edu (serre-lab.clps.brown.edu)|128.148.254.114|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://serre-lab.clps.brown.edu/wp-content/uploads/2013/10/test_train_splits.rar [following]\n",
            "--2020-09-20 06:00:05--  https://serre-lab.clps.brown.edu/wp-content/uploads/2013/10/test_train_splits.rar\n",
            "Connecting to serre-lab.clps.brown.edu (serre-lab.clps.brown.edu)|128.148.254.114|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 199521 (195K)\n",
            "Saving to: ‘test_train_splits.rar’\n",
            "\n",
            "test_train_splits.r 100%[===================>] 194.84K   700KB/s    in 0.3s    \n",
            "\n",
            "2020-09-20 06:00:05 (700 KB/s) - ‘test_train_splits.rar’ saved [199521/199521]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nuukMfDiGoMg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import required modules ...\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "from torch.utils.data import random_split, DataLoader\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "import torchvision\n",
        "from torchvision import get_video_backend\n",
        "from torchvision.models.video import r3d_18 \n",
        "from torchvision import transforms\n",
        "import os\n",
        "from tqdm.auto import tqdm\n",
        "import numpy as np\n",
        "import time\n",
        "#import av\n",
        "import random\n",
        "#print(f\"PyAV version -- {av.__version__}\")\n",
        "\n",
        "SEED = 491\n",
        "torch.manual_seed(SEED)\n",
        "\n",
        "from collections import OrderedDict\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "#run_av_diagnostics()"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NTYQ_kYdFbi3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "outputId": "a3904d54-6daf-4e86-cd60-2a020f50733e"
      },
      "source": [
        "# Extract and organize video data..\n",
        "! mkdir -p video_data test_train_splits\n",
        "! unrar e test_train_splits.rar test_train_splits\n",
        "! rm test_train_splits.rar\n",
        "! unrar e hmdb51_org.rar \n",
        "! rm hmdb51_org.rar\n",
        "! mv *.rar video_data\n",
        "for files in os.listdir('video_data'):\n",
        "    foldername = files.split('.')[0]\n",
        "    os.system(\"mkdir -p video_data/\" + foldername)\n",
        "    os.system(\"unrar e video_data/\"+ files + \" video_data/\"+foldername)\n",
        "\n",
        "! rm video_data/*.rar "
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "UNRAR 5.50 freeware      Copyright (c) 1993-2017 Alexander Roshal\n",
            "\n",
            "Cannot open test_train_splits.rar\n",
            "No such file or directory\n",
            "No files to extract\n",
            "rm: cannot remove 'test_train_splits.rar': No such file or directory\n",
            "\n",
            "UNRAR 5.50 freeware      Copyright (c) 1993-2017 Alexander Roshal\n",
            "\n",
            "Cannot open hmdb51_org.rar\n",
            "No such file or directory\n",
            "No files to extract\n",
            "rm: cannot remove 'hmdb51_org.rar': No such file or directory\n",
            "mv: cannot stat '*.rar': No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gSIfSY4LFbn5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2622e9a8-13c2-4cd2-d6eb-0b230b2ba34d"
      },
      "source": [
        "# diagnostics for PyAV installation. For now version 6.2.0 works \n",
        "def run_av_diagnostics():\n",
        "    import av\n",
        "    av.open(\"video_data/brush_hair/Aussie_Brunette_Brushing_Hair_II_brush_hair_u_nm_np1_ba_goo_4.avi\")\n",
        "    print(get_video_backend())\n",
        "    av.logging.set_level(av.logging.ERROR)\n",
        "    if not hasattr(av.video.frame.VideoFrame, 'pict_type'):\n",
        "      print(\"Nah\")\n",
        "\n",
        "run_av_diagnostics()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "pyav\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sui0d5y_Fk4u",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "outputId": "021e5910-756b-4cbc-d966-04be60478e3f"
      },
      "source": [
        "# memory footprint support libraries/code\n",
        "!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
        "!pip install gputil\n",
        "!pip install psutil\n",
        "!pip install humanize\n",
        "\n",
        "import psutil\n",
        "import humanize\n",
        "import os\n",
        "import GPUtil as GPU\n",
        "\n",
        "GPUs = GPU.getGPUs()\n",
        "# XXX: only one GPU on Colab and isn’t guaranteed\n",
        "gpu = GPUs[0]\n",
        "def printm():\n",
        "    process = psutil.Process(os.getpid())\n",
        "    print(\"Gen RAM Free: \" + humanize.naturalsize(psutil.virtual_memory().available), \" |     Proc size: \" + humanize.naturalsize(process.memory_info().rss))\n",
        "    print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total     {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n",
        "printm()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting gputil\n",
            "  Downloading https://files.pythonhosted.org/packages/ed/0e/5c61eedde9f6c87713e89d794f01e378cfd9565847d4576fa627d758c554/GPUtil-1.4.0.tar.gz\n",
            "Building wheels for collected packages: gputil\n",
            "  Building wheel for gputil (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gputil: filename=GPUtil-1.4.0-cp36-none-any.whl size=7411 sha256=ac17c4bfa22e8792a65f739927b2e3ee36eaa191a652d078d86113abc0d5c534\n",
            "  Stored in directory: /root/.cache/pip/wheels/3d/77/07/80562de4bb0786e5ea186911a2c831fdd0018bda69beab71fd\n",
            "Successfully built gputil\n",
            "Installing collected packages: gputil\n",
            "Successfully installed gputil-1.4.0\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.6/dist-packages (5.4.8)\n",
            "Requirement already satisfied: humanize in /usr/local/lib/python3.6/dist-packages (0.5.1)\n",
            "Gen RAM Free: 12.7 GB  |     Proc size: 282.2 MB\n",
            "GPU RAM Free: 15079MB | Used: 0MB | Util   0% | Total     15079MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2zAUkbBIFQFr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BoQWFA_-Fnf1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 209
        },
        "outputId": "d933608b-5329-45fe-975b-0cfb40517b0e"
      },
      "source": [
        "# download video transformation functions from below link\n",
        "! wget https://raw.githubusercontent.com/pytorch/vision/6de158c473b83cf43344a0651d7c01128c7850e6/references/video_classification/transforms.py\n",
        "import transforms as T"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-09-20 06:02:24--  https://raw.githubusercontent.com/pytorch/vision/6de158c473b83cf43344a0651d7c01128c7850e6/references/video_classification/transforms.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3102 (3.0K) [text/plain]\n",
            "Saving to: ‘transforms.py’\n",
            "\n",
            "\rtransforms.py         0%[                    ]       0  --.-KB/s               \rtransforms.py       100%[===================>]   3.03K  --.-KB/s    in 0s      \n",
            "\n",
            "2020-09-20 06:02:25 (47.1 MB/s) - ‘transforms.py’ saved [3102/3102]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uQk3zvPd9AUX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class ConvLSTM(nn.Module):\n",
        "    def __init__(self, n_in, output_channel, class_num, in_ch):\n",
        "        super(ConvLSTM, self).__init__()\n",
        "        self.in_ch = in_ch\n",
        "        self.n_in   = n_in\n",
        "        self.out_ch = output_channel \n",
        "        self.rnn1 = Conv_LSTM(input_channel = self.in_ch, output_channel = self.out_ch)\n",
        "        self.ap = nn.AvgPool1d(32,32, padding=0)\n",
        "        self.fcl1 = nn.Linear(self.out_ch * self.n_in // 32, class_num, bias = False)\n",
        "        \n",
        "                \n",
        "    def forward(self, x, hidden):\n",
        "        h1 = hidden\n",
        "        x = x.reshape(-1, self.in_ch, self.n_in)\n",
        "        x, h1 = self.rnn1(x, h1)\n",
        "        x = F.relu(x)\n",
        "        x = self.ap(x)\n",
        "        x = x.view(-1, self.out_ch * self.n_in // 32)\n",
        "        x = self.fcl1(x)\n",
        "        hidden = h1\n",
        "                \n",
        "        return x, hidden\n",
        "\n",
        "class Conv_LSTM(nn.Module):\n",
        "    def __init__(self, input_channel, output_channel):\n",
        "        super(Conv_LSTM, self).__init__()\n",
        "        self.output_channel = output_channel\n",
        "        self.fcl_wxf = nn.Conv1d(input_channel,output_channel, 9, stride=1, bias = False, padding = 4)\n",
        "        self.fcl_wxi = nn.Conv1d(input_channel,output_channel, 9, stride=1, bias = False, padding = 4)\n",
        "        self.fcl_wxo = nn.Conv1d(input_channel,output_channel, 9, stride=1, bias = False, padding = 4)\n",
        "        self.fcl_wxg = nn.Conv1d(input_channel,output_channel, 9, stride=1, bias = False, padding = 4)\n",
        "        self.fcl_whf = nn.Conv1d(output_channel,output_channel, 9, stride=1, bias = False, padding = 4)\n",
        "        self.fcl_whi = nn.Conv1d(output_channel,output_channel, 9, stride=1, bias = False, padding = 4)\n",
        "        self.fcl_who = nn.Conv1d(output_channel,output_channel, 9, stride=1, bias = False, padding = 4)\n",
        "        self.fcl_whg = nn.Conv1d(output_channel,output_channel, 9, stride=1, bias = False, padding = 4)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        h_t_1, c_t_1 = hidden\n",
        "        f_t_i = (self.fcl_wxf(input) + self.fcl_whf(h_t_1))\n",
        "        i_t_i = (self.fcl_wxi(input) + self.fcl_whi(h_t_1))\n",
        "        g_t_i = (self.fcl_wxg(input) + self.fcl_whg(h_t_1))\n",
        "        o_t_i = (self.fcl_wxo(input) + self.fcl_who(h_t_1))\n",
        "\n",
        "        f_t = torch.sigmoid(f_t_i)\n",
        "        i_t = torch.sigmoid(i_t_i)\n",
        "        g_t = torch.tanh(g_t_i)\n",
        "        o_t = torch.sigmoid(o_t_i)\n",
        "                \n",
        "        c_t = f_t * c_t_1 + i_t * g_t\n",
        "        h_t = o_t * torch.tanh(c_t)\n",
        "        output = h_t\n",
        "        hidden = (h_t, c_t)\n",
        "        \n",
        "        return output, hidden\n",
        "        \n",
        "    def initHidden(self, batch_size, seg_size):\n",
        "        weight = next(self.parameters())\n",
        "        return (weight.new_zeros(batch_size, self.output_channel, seg_size),\n",
        "                weight.new_zeros(batch_size, self.output_channel, seg_size))  "
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JSYSVps1GEWN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}